{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ec725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import avg, max\n",
    "from pyspark.sql.functions import avg, max, round as spark_round\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "class ChargePointsETLJob:\n",
    "    input_path = 'C:\\\\Users\\\\Anhnh\\\\OneDrive\\\\Documents\\\\MayoCodility\\\\electric-chargepoints-2017.csv'\n",
    "    output_path = 'C:\\\\Users\\\\Anhnh\\\\OneDrive\\\\Documents\\\\MayoCodility\\\\chargepoints-2017-analysis'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.spark_session = (SparkSession.builder\n",
    "                                          .master(\"local[*]\")\n",
    "                                          .appName(\"ElectricChargePointsETLJob\")\n",
    "                                          .getOrCreate())\n",
    "\n",
    "    def extract(self, input_path=None):\n",
    "        if input_path is None:\n",
    "            input_path = self.input_path\n",
    "        return self.spark_session.read.option(\"header\", True).csv(input_path)\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df.groupBy(\"CPID\") \\\n",
    "                .agg(\n",
    "                     spark_round(max(\"PluginDuration\"), 2).alias(\"max_duration\"),\n",
    "                    spark_round(avg(\"PluginDuration\"), 2).alias(\"avg_duration\")\n",
    "                ) \\\n",
    "                .withColumnRenamed(\"CPID\", \"chargepoint_id\")\n",
    "\n",
    "    def load(self, df, output_path=None):\n",
    "        if output_path is None:\n",
    "            output_path = self.output_path\n",
    "        print(\"[INFO] Previewing transformed data...\")\n",
    "        df.show(truncate=False)\n",
    "        print(\"[INFO] Done.\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"[STEP] Reading file...\")\n",
    "        df = self.extract()\n",
    "\n",
    "        print(\"[STEP] Transforming data...\")\n",
    "        transformed_df = self.transform(df)\n",
    "\n",
    "        print(\"[STEP] Showing transformed data:\")\n",
    "        transformed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d2c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(ChargePointsETLJob.input_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7004e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self):\n",
    "    print(\"[STEP] Reading file...\")\n",
    "    df = self.spark_session.read.option(\"header\", True).csv(self.input_path)\n",
    "    \n",
    "    print(\"[STEP] File read, showing schema:\")\n",
    "    df.printSchema()\n",
    "\n",
    "    print(\"[STEP] Previewing data:\")\n",
    "    df.show(5)\n",
    "\n",
    "    print(\"[STEP] Transforming:\")\n",
    "    transformed_df = self.transform(df)\n",
    "    \n",
    "    print(\"[STEP] Showing transformed data:\")\n",
    "    transformed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75626dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] JAVA_HOME = C:\\Program Files\\Java\\jdk-17.0.15_6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"[DEBUG] JAVA_HOME =\", os.environ.get(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2802686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Starting Spark...\n",
      "[TEST] Spark started.\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"[TEST] Starting Spark...\")\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"TestSpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"[TEST] Spark started.\")\n",
    "spark.range(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e682d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] Reading file...\n",
      "[STEP] Transforming data...\n",
      "[STEP] Showing transformed data:\n",
      "+--------------+------------+------------+\n",
      "|chargepoint_id|max_duration|avg_duration|\n",
      "+--------------+------------+------------+\n",
      "|       AN00019|      480.37|      257.35|\n",
      "|       AN00056|        1.67|        0.84|\n",
      "|       AN00073|       22.42|       35.91|\n",
      "|       AN00080|       21.25|       16.88|\n",
      "|       AN00093|       25.49|       12.73|\n",
      "|       AN00098|        3.63|       11.77|\n",
      "|       AN00116|       45.03|       28.64|\n",
      "|       AN00119|       40.84|       21.01|\n",
      "|       AN00158|       20.17|       16.92|\n",
      "|       AN00159|        9.18|       15.94|\n",
      "|       AN00170|       27.08|       20.25|\n",
      "|       AN00210|       14.37|        9.43|\n",
      "|       AN00218|        3.46|        1.56|\n",
      "|       AN00230|        3.31|        9.09|\n",
      "|       AN00231|        8.92|        7.39|\n",
      "|       AN00233|        2.55|        9.96|\n",
      "|       AN00249|         7.7|       16.27|\n",
      "|       AN00254|        19.2|       16.35|\n",
      "|       AN00257|        9.85|        4.78|\n",
      "|       AN00262|        7.57|       10.99|\n",
      "+--------------+------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    job = ChargePointsETLJob()\n",
    "    job.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
